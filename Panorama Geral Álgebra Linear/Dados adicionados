A disciplina de Álgebra Linear Computacional possuí o foco em explorar recursos computacionais envolvendo equações matriciais. Desse modo, sendo apresentado métodos como: Eliminação Gaussiana, a qual consiste em o sistema linear obtido por meio desse processo estar em uma forma escalonado e a matriz associada a este novo sistema  chamada ser triangular superior, contudo, possuindo problemas computacionais durantes os cálculos quando o determinante é próximo de zero. A Eliminação Gaussiana com pivoteamento é bem semelhante ao anterior, apresentando como mudança a inclusão do pivoteamento que consiste em escolher o maior pivô (em módulo), em cada etapa k, e se for necessário, realizar as devidas trocas das linhas, assim, apresentando dois tipos de pivoteamentos, o parcial, mais usual, e o completo que demanda maior esforço computacional. Portanto, sendo eficaz para inibir problemas como a divisão por zero, e sendo mais completo que o método anterior. 

Além disso, a Decomposição LU é um método que resolve uma sequência de sistemas lineares que são mais simples de
se resolver do que a original Ax = b, por meio de L que é uma matriz triangular inferior e U que é uma matriz triangular superior, ademais, a vantagem desse tipo de processo é que podemos resolver qualquer sistema linear que tenha A como matriz dos coeficientes, e se o vetor b for alterado, então a resolução do novo sistema é obtido praticamente de forma imediata. Já Decomposição LU com pivoteamento parcial sua função é quase a mesma, e sendo funcional em matrizes de permutação, as quais esse pivoteamento é necessário, assim, armazenando as trocas de linhas ou colunas.

Seguindo os métodos, temos a Fatoração Cholesky que pode
ser realizada para matrizes simétricas definidas positivas, onde uma matriz A é chamada de simétrica definida positiva se satisfaz: A = A**t e x**t Ax > 0 para todo vetor x, em que x**t é uma matriz linha. Desse modo, a decomposição de Cholesky requer aproximadamente a metade das operações do método de decomposição LU e os elementos da diagonal principal da matriz G são sempre positivos, implicando em que, caso a decomposição exista então a matriz G da decomposição é única. Ademais, a Decomposição em Valores Singulares (SVD) pode ser fatorada da seguinte forma: A = QDQ**t, para matizes quadradas, e de forma geral A = UDV**t, possuindo autovetores e autovalores. Nessa perspectiva, sendo util em casos como  simplificar os dados, remoção de ruídos e na parte de  compressão de imagens, além disso, algo a salientar é que a matriz diagonal não precisa ser necessariamente quadrada, basta que aij = 0 para todo i diferente de j, e por meio desse método sendo bem eficaz para a resolução de quase todos os problemas e sem um custo computacional elevado.

Por fim, os Interpoladores, cujo proposito é a utilização para aproximar uma função f(x) por uma outra g(x), sendo a função g(x) com propriedades melhores de serem trabalhadas. Portanto,
 os Interpoladores polinomiais possuem pontos em que as funções f e g coincidem, ademais, A matriz A é chamada de matriz de Vandermonde. Assim, só será possível obter únicos coeficientes para o polinômio p, se a matriz de Vandermonde tiver determinante diferente de 0. Contudo, a matriz de Vandermonde pode ser, por muitas vezes, uma matriz mal condicionada. Nesse viés, o Interpolador de Lagrange evita essas matrizes má condicionadas e retorna o mesmo polinômio interpolador que no método anterior, isso ilustra o fato de que o polinômio produzido pelo processo de interpolação é sempre único. Ademais, o Fenômeno de Runge pretende  construir um polinômio p de tal forma que f(x) = p(x), para todo x de seu domínio, todavia, não necessariamente temos que tal construção produza um polinômio p que convirja para f em todo o seu domínio, já que, quanto maior o grau n do polinômio e levando em conta as suas extremidades, partes fora do intervalo, maior será essa dispersão, o qual é minimizado pelo método de Interpolação por meio de nós de Chebyshev. Para concluir, temos os Quadrados Mínimos que evitam essa grande extrapolação de dados em certo intervalo, dividindo, assim, de forma compatível entre os dados, portanto, os Quadrados mínimos no caso discreto, representam a construção a partir da noção de estimativa de erro. Onde se as funções de base gi forem linearmente independentes, então o determinante da matriz A é diferente de zero, isto é, A é invertível, isso implica que existirá solução única para o
problema. Ademais, os valores encontrados para esses coeficientes de fato minimizam o erro.
